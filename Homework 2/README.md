# Homework for Lecture 2

## Problem 1ðŸŒŸ:

Carefully study the backpropagation algorithm, on paper and in the program



## Problem 2ðŸŒŸ:

Visualize the training of a multi-layer network for some interesting function! Explore reLU vs sigmoid!

## Problem 3ðŸ› :

Analyze the evolution of the slope w during stochastic gradient descent on a cost function given by <img src="https://render.githubusercontent.com/render/math?math=C=(1/2) \sum_j (w x_j - \tilde w x_j)^2">  ï¿¼, where ï¿¼<img src="https://render.githubusercontent.com/render/math?math=x_j">are the N samples drawn from a Gaussian distribution in a single training step. (this is an **advanced** exercise)



---

<sup>ðŸŒŸ</sup>: Suggested by [Dr. Florian Marquardt](https://scholar.google.com/citations?user=jx_c7SgAAAAJ&hl=en&oi=ao) (Essential)

<sup>ðŸ› </sup>: Advanced exercise